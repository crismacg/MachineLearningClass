{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING FOR PUBLIC POLICY\n",
    "# Homework 3 - Cristina Mac Gregor Vanegas\n",
    "### Due: May 17, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1.A:\n",
    "     1. Generating auxiliary functions for feature manipulation and generation\n",
    "     2. Generating functions for exploration of data\n",
    "#### Part 1.B: \n",
    "     3. Building functions for applying classifiers  \n",
    "#### Part 1.C:\n",
    "     4. Building functions for evaluating classifiers \n",
    "#### Part 1.D:\n",
    "     5. Preparation for loop. \n",
    "#### Part 2: \n",
    "     Running the pipeline\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1.A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up and import of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacgregor/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/crismacgregor/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import product\n",
    "from sklearn import preprocessing, cross_validation, svm, metrics, tree, decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_files(file_name):\n",
    "    '''\n",
    "    Reading in downloaded csv files.\n",
    "    '''\n",
    "    dframe = pd.read_csv(file_name)\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_frames(frame1, frame2, id1, id2) :\n",
    "    frame2 = frame2.rename(columns={id2: id1})\n",
    "    frame = pd.merge(frame1, frame2, on=id1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo(shape_file, frame, var, shp_name, level_str):\n",
    "    '''\n",
    "    Creates a geopandas file at the geographical level specified, given a pandas\n",
    "    dataframe and a shape or geojson file.\n",
    "    Inputs: shape_file: shapefile or geojson file\n",
    "            frame: pandas frame\n",
    "            shp_name: name of column in geojson file\n",
    "            level_str: name of column in frame\n",
    "    Outputs:\n",
    "        Extended geo frame (geopandas object)\n",
    "\n",
    "    '''\n",
    "    frame.groupby()\n",
    "    geo_df = gpd.read_file(shape_file)\n",
    "    geo_df = geo_df.rename(columns={shp_name: level_str})\n",
    "    geo_df_ext = geo_df.merge(frame, on=level_str, how = 'left')\n",
    "    return geo_df_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Pre-processing auxiliary data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_mv(frame, var):\n",
    "    '''\n",
    "    Prints out percentage of missing values for a given variable.\n",
    "    '''\n",
    "    frame[\"temp\"] = frame[var].apply(lambda x: x if float(x) else np.nan)\n",
    "    frame[\"temp2\"] = frame[var].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "    print(\"Missing values\", frame[\"temp2\"].value_counts(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_mvals(frame, var, measure = \"mean\"):\n",
    "    '''\n",
    "    Setting missing values to a meassure of central distribution as specified by parameters.  \n",
    "    '''\n",
    "    if measure == \"median\":\n",
    "        md = frame[var].median()\n",
    "    elif measure == \"mean\":\n",
    "        md = frame[var].mean()\n",
    "    frame[var] = frame[var].apply(lambda x: md if pd.isnull(x) else x) \n",
    "    return frame, md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(frame, var, level = .99):\n",
    "    '''\n",
    "    Winzorizing process: setting outliers to the value of the 99 percentile. \n",
    "    '''\n",
    "    cuttoff = frame[var].quantile(level)\n",
    "    frame[var] = frame[var].apply(lambda x: cuttoff if x > cuttoff else x) \n",
    "    return frame, cuttoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_buckets(frame, var, nbuckets):\n",
    "    '''\n",
    "    Auxiliary function for discretization. Generates equally sized bins for a variable according \n",
    "    to the number of bins specified as a parameter. \n",
    "    Returns a list with the upper boundries for every bucket. \n",
    "    '''\n",
    "    min_ = frame[var].min()\n",
    "    max_ = frame[var].max()\n",
    "    step = (max_  - min_ ) / nbuckets\n",
    "    steps = []\n",
    "    temp = min_\n",
    "    while temp <= max_:\n",
    "        temp += step \n",
    "        steps += temp\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cats(row, buckets, var):\n",
    "    '''\n",
    "    Auxiliary variable for discretization. Returns category to which a variable corresponds \n",
    "    if its being classified into buckets. \n",
    "    '''\n",
    "    last = 0 \n",
    "    gr = 1\n",
    "    for i in buckets: \n",
    "        if (row[var]<= i) and (row[var]> last): \n",
    "            return gr\n",
    "        gr += 1\n",
    "        last = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretize(frame, var, buckets = None, quartiles = False, num_buckets = None):\n",
    "    '''\n",
    "    Returns a discrete variable. If buckets are specified, they are used as thresholds. If not, \n",
    "    quartiles can be used to discretize a continious variable. If neither buckets nor quartiles \n",
    "    are specified, number of equal sized buckets can be used.\n",
    "    '''\n",
    "    new_name = str(var) + \"_discrete\" \n",
    "    \n",
    "    if quartiles:     \n",
    "        x25 = frame[var].quantile(.25)    \n",
    "        x50 = frame[var].quantile(.50)    \n",
    "        x75 = frame[var].quantile(.75)\n",
    "        x100 = frame[var].max()\n",
    "        buckets = [x25, x50, x75, x100]\n",
    "    \n",
    "    if num_buckets: \n",
    "        buckets = generate_buckets(frame, var, num_buckers)\n",
    "        \n",
    "    frame[new_name] = frame.apply(cats, axis=1, args = (buckets, var)) \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummify(frame, var, threshold = None):\n",
    "    '''\n",
    "    Makes dummy variables for each category of a discrete variable.\n",
    "    '''\n",
    "    if threshold: \n",
    "        new_name = str(var) + \"_d\" \n",
    "        frame[new_name] = frame.apply(lambda x: 1 if x[var] < threshold else 0)\n",
    "    else:\n",
    "        buckets = frame[var].unique()\n",
    "        for i in buckets: \n",
    "            new_name = str(var) + \"_d_\" + str(i)\n",
    "            frame[new_name] = frame[var].apply(lambda x: 1 if x == i else 0)\n",
    "            \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cases(row, frame, plusminus_range, var):\n",
    "    '''\n",
    "    Counts how many cases fit within a given range. \n",
    "    '''\n",
    "    min_time = row[var] - plusminus_range \n",
    "    max_time = row[var] + plusminus_range \n",
    "    count = frame[(row[var] >= min_time) and (row[var] <= max_time)].count()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Functions for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(frame, target_var, group_vars = None):\n",
    "    '''\n",
    "    Prints general statistics for each variable, and if specified, also \n",
    "    means of grouped-by varibales, grouped by specified groups. \n",
    "    '''\n",
    "    \n",
    "    if not group_vars:\n",
    "        print(\"\\n\", target_var, frame[target_var].describe())\n",
    "        print(frame[target_var].value_counts(True))\n",
    "    \n",
    "    if group_vars: \n",
    "        print(frame.groupby(group_vars)[target_var].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_map_byvar(frame, varbs):\n",
    "    '''\n",
    "    Plots a map of the geographic distribution of the variables we wish to see. \n",
    "    '''\n",
    "    for i in varbs:\n",
    "        geo_df.plot(column=i, cmap='OrRd')\n",
    "        plt.title(i)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cor(frame):\n",
    "    '''\n",
    "    Prints spearman correlations from a complete dataframe\n",
    "    '''\n",
    "    return frame.corr(\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scat(frame, varbs, target_var):\n",
    "    '''\n",
    "    Prints scatter plots for all the possible features against the predicted variable. \n",
    "    '''\n",
    "    pairs = []\n",
    "    for i in varbs:\n",
    "        plt.scatter(frame[target_var], frame[i])\n",
    "        plt.title(\"{} vs {}\".format(target_var, i))\n",
    "        plt.xlabel(target_var)\n",
    "        plt.ylabel(i)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1.B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Functions for building classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_feats(varbs, frame):\n",
    "    '''\n",
    "    Keeps features we want to include as predicitve features\n",
    "    '''\n",
    "    f2 = frame[varbs]\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_feats(varbs, frame):\n",
    "    '''\n",
    "    Deletes variables that we don't want to include as predicitve features\n",
    "    '''\n",
    "    f2 = frame.drop(varbs, axis=1)\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(frame, test_percentage, target_var):\n",
    "    '''\n",
    "    Splits data into train and test sections. \n",
    "    '''\n",
    "    X = frame.drop(target_var, axis=1)\n",
    "    Y = frame[target_var]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_percentage)\n",
    "\n",
    "    return  [x_train, x_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Functions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conf_matrix(output_array, real_vals, threshold):\n",
    "    '''\n",
    "    Returns the confussion matrix according to the test\n",
    "    predictions and true values, according to a given threshold. \n",
    "    Inputs:\n",
    "        output_array: (array) predicted values from test fraction of the data\n",
    "        real_vals: (array) true values from test fraction of data (y_test)\n",
    "        threshold: (float) threshold for predicted probabilities. \n",
    "    Outputs: \n",
    "        list [TP, FP, TN, FN]\n",
    "    '''\n",
    "    test = {'pred': output_array, 'real': real_vals}\n",
    "    test_f = pd.DataFrame(data=test)   \n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    for indx, row in test_f.iterrows():\n",
    "        status_predicted = 0\n",
    "        if row[\"pred\"] > threshold:\n",
    "            status_predicted= 1 \n",
    "        if (status_predicted == 1) and (row[\"real\"]==1):\n",
    "            TP += 1\n",
    "        if (status_predicted == 1) and (row[\"real\"]==0):\n",
    "            FP += 1\n",
    "        if (status_predicted == 0) and (row[\"real\"]==0):\n",
    "            TN += 1\n",
    "        if (status_predicted == 0) and (row[\"real\"]==1):\n",
    "            FN += 1\n",
    "            \n",
    "    return [TP, FP, TN, FN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(conf_m):\n",
    "    TP, FP, TN, FN = conf_m[0], conf_m[1], conf_m[2], conf_m[3]\n",
    "    if (TP + TN + FP + FN) == 0: \n",
    "        return 0\n",
    "    acc =  (TP + TN) / (TP + TN + FP + FN)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(conf_m):\n",
    "    TP, FP, TN, FN = conf_m[0], conf_m[1], conf_m[2], conf_m[3]\n",
    "    if (TP + FN) == 0: \n",
    "        return 0\n",
    "    rec =  (TP) / (TP + FN)\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(conf_m):\n",
    "    TP, FP, TN, FN = conf_m[0], conf_m[1], conf_m[2], conf_m[3]\n",
    "    if (TP + FP )== 0: \n",
    "        return 0\n",
    "    prec = (TP) / (TP + FP )\n",
    "    return prec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(conf_m): \n",
    "    TP, FP, TN, FN = conf_m[0], conf_m[1], conf_m[2], conf_m[3]\n",
    "    if (TN + FN) == 0:\n",
    "        return  0\n",
    "    spec = (TN) / (TN + FN)\n",
    "    return spec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(prec, rec): \n",
    "    if (prec + rec) == 0:\n",
    "        return 0\n",
    "    return 2 * (prec * rec) / (prec + rec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_metrics(output_array, real_vals, cuttoff):\n",
    "    cm = conf_matrix(output_array, real_vals, cuttoff)\n",
    "    recall_m = recall(cm)\n",
    "    precision_m = precision(cm)\n",
    "    accuracy_m = accuracy(cm)\n",
    "    specificity_m = specificity(cm)\n",
    "    f1_ = f1(precision_m, recall_m)\n",
    "    return recall_m, precision_m, accuracy_m, specificity_m, f1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_array(output_array, real_vals, steps = 20):\n",
    "    recall_arr = []\n",
    "    precision_arr = []\n",
    "    acc_arr = []\n",
    "    spec_arr = []\n",
    "    for i in range (0, 100, steps):\n",
    "        r, p, a, s, f = get_main_metrics(output_array, real_vals, i/100)\n",
    "        recall_arr += [r]\n",
    "        precision_arr += [p]\n",
    "        acc_arr += [a]\n",
    "        spec_arr  += [s]\n",
    "    return recall_arr, precision_arr, acc_arr, spec_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_rec(output_array, real_vals):\n",
    "    r_arr, p_arr, a_arr, s_arr = get_metrics_array(output_array, real_vals)\n",
    "    \n",
    "    plt.step(r_arr, p_arr, color='a', alpha=0.2, where='post')\n",
    "    plt.fill_between(r_arr, p_arr, step='post', alpha=0.2, color='a')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_rec_auc(output_array, real_vals):\n",
    "    r_arr, p_arr, a_arr, s_arr = get_metrics_array(output_array, real_vals)\n",
    "    area =  metrics.auc(r_arr, p_arr)\n",
    "    return area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(output_array, real_vals):\n",
    "    \n",
    "    area = roc_auc_score(output_array, real_vals)\n",
    "    return area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(mode, real_vals):\n",
    "    mode = frame['pred_var'].mode()\n",
    "    return mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions for creating models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "From DSSG Magic loop - different values for each model. \n",
    "Reference: DSSG magic loop; source https://github.com/rayidghani/magicloops\n",
    "\n",
    "'''\n",
    "fn = {  'RF': RandomForestClassifier,\n",
    "        'LR': LogisticRegression,\n",
    "        'SVM': svm.SVC,\n",
    "        'GB': GradientBoostingClassifier,\n",
    "        'DT': DecisionTreeClassifier,\n",
    "        'KNN': KNeighborsClassifier\n",
    "            }\n",
    "small_grid = { \n",
    "        'RF':{'n_estimators': [10,100], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "        'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.001,0.1,1,10]},\n",
    "        'GB': {'n_estimators': [10,100], 'learning_rate' : [0.001,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [5,50]},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "        'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "        'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time(frame, cuttoff, target_var, time_var):\n",
    "    '''\n",
    "    Splits data into train and test sections. \n",
    "    Reference: DSSG magic loop; source https://github.com/rayidghani/magicloops\n",
    "    '''    \n",
    "    train = frame[frame[time_var] <= cuttoff]\n",
    "    train = train.drop(time_var, axis=1)\n",
    "    x_train = train.drop(target_var, axis=1)\n",
    "    y_train = train[target_var]\n",
    "    \n",
    "    test = frame[frame[time_var] > cuttoff]\n",
    "    test = test.drop(time_var, axis=1)\n",
    "    x_test = test.drop(target_var, axis=1)\n",
    "    y_test = test[target_var]\n",
    "\n",
    "    return  [x_train, x_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split(raw_split):\n",
    "    xtr, xtst, ytr, ytst = raw_split[0], raw_split[1], raw_split[2], raw_split[3]\n",
    "    for i in xtr.columns.values:\n",
    "        \n",
    "        xtr[i], md = fill_mvals(xtr, i, \"mean\")\n",
    "        xtr[i], cut = winsorize(xtr, i, \"mean\")\n",
    "        \n",
    "        ytr[i] = frame[i].apply(lambda x: md if pd.isnull(x) else x) \n",
    "        ytr[i] = frame[i].apply(lambda x: cut if x > cuttoff else x) \n",
    "    \n",
    "    return [xtr, xtst, ytr, ytst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_evaluation_loop(fn, models_to_run, model_grid, thresholds_given, split):\n",
    "    '''\n",
    "    '''\n",
    "    d = {}\n",
    "    \n",
    "    for model, params in model_grid.items():\n",
    "        if model in models_to_run: \n",
    "            combinations_vals  = {}\n",
    "            count = 0\n",
    "            parameters  = []\n",
    "            for ind, val in params.items():\n",
    "                count += 1\n",
    "                parameters += [ind]\n",
    "                combinations_temp = []\n",
    "                for i in val: \n",
    "                    combinations_temp += [i]\n",
    "                combinations_vals[count] = combinations_temp\n",
    "                combinations_params = list(product(*combinations_vals.values())) \n",
    "            list_values = []\n",
    "\n",
    "            for idx, item in enumerate(combinations_params): \n",
    "                d['model'] = model\n",
    "                d['parameters'] = str(parameters) +' = '+ str(item)\n",
    "                item = list(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(fn, model, keys, values, split):\n",
    "    '''\n",
    "    Visited for information about ziping\n",
    "    https://stackoverflow.com/questions/209840/map-two-lists-into-a-dictionary-in-python\n",
    "    '''\n",
    "    \n",
    "    x_tr, x_tst, y_tr, y_tst = split[0], split[1], split[2], split[3]\n",
    "    skfunction = fn[model]()\n",
    "    \n",
    "    params = dict(zip(keys, values))\n",
    "    print(params)\n",
    "    skfunction.set_params(**params)\n",
    "    preds = skfunction.fit(x_tr, y_tr).predict_proba(x_tst)\n",
    "    return preds[:,1], y_tst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Processing inital data\n",
    "'''\n",
    "fr1 = read_files('data/projects.csv')\n",
    "fr2 = read_files('data/outcomes.csv')\n",
    "fr = merge_frames(fr1, fr2, 'projectid', 'projectid')\n",
    "fr['Year'] = pd.to_datetime(fr['date_posted']).dt.year\n",
    "fr['date_posted'] = pd.to_datetime(fr['date_posted'])\n",
    "\n",
    "fr = fr[(fr['Year'] >= 2011 )] \n",
    "fr = fr[(fr['Year'] <= 2014 )] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting globals \n",
    "\n",
    "fr = drop_feats(['projectid', 'teacher_acctid', 'schoolid', 'school_ncesid', 'school_latitude',\n",
    " 'school_longitude'], fr)\n",
    "all_cols = list(fr.columns.values)\n",
    "pred_vr = 'fully_funded'\n",
    "time_cuttoff = datetime.strptime('2013-10-01', '%Y-%m-%d' )\n",
    "time_var =  'date_posted'\n",
    "models = ['RF', 'LR', 'SVM','GB','DT','KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory analysis\n",
    "scat(fr, all_cols, pred_vr)\n",
    "for i in all_cols: \n",
    "    get_stats(fr,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cor(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat(fr, all_cols, pred_vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTING UP DATA\n",
    "bool_features = ['school_charter_ready_promise',\n",
    " 'teacher_teach_for_america', 'at_least_1_teacher_referred_donor']\n",
    "\n",
    "for var in (bool_features += [pred_vr]): \n",
    "    fr[var] = fr[var].apply(lambda x: '0' if (x == 'f') else '1')\n",
    "\n",
    "ind_features = bool_features += ['students_reached', 'school_zip','total_price_excluding_optional_support' ]\n",
    "\n",
    "feats_tokeep = ind_features += [time_var] += [pred_vr]\n",
    "test_frame = keep_feats(feats_tokeep, fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_split = split_time(test_frame, time_cuttoff, pred_vr,time_var)\n",
    "split = process_split(raw_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNING LOOP\n",
    "dict_models = complete_evaluation_loop(fn, models, small_grid, [.01, .02, .05, .10, .20, .30, .50], split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df =  pd.DataFrame(columns=('model_type','clf', 'parameters', 'outcome', 'validation_date', 'group',\n",
    "                                        'train_set_size', 'validation_set_size','predictors',\n",
    "                                        'baseline','precision_at_5','precision_at_10','precision_at_20','precision_at_30','precision_at_40',\n",
    "                                        'precision_at_50','recall_at_5','recall_at_10','recall_at_20','recall_at_30','recall_at_40',\n",
    "                                        'recall_at_50','auc-roc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
