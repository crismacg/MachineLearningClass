Assignment 2, Cristina Mac Gregor


For this assignment, I worked on a Jupyter notebook, and organized it in the following way:
It includes first, all functions created in order to carry out the analysis are defined in the folowing order:
Part 1.A.:

    1. Read Data functions:

    -read_files reads a csv and makes a pandas dataframe that corresponds to it.

    2. Exploring and pre-prcocessing data functions:

    -check_mv checks missing values and prints out the percentages of missing values for a specified variable.
    -clean_var: winsorizes outliers and fills in missing values with the media of specified frame.
    -get_stats:  Prints general statistics for each variable, and if specified, also means of grouped-by varibales, grouped by specified groups.
    -get_geo and print_map_byvar: allows to merge with a shapefile in order to print density maps for given variables. (this is not done for this assignment)
    -show_cor: prints spearman correlation matrix between the variables that compose a frame.
    -scat: prints scatter plots between a list of variables and a dependent variable.

    3. Generate features functions:

    -discretize_quartiles: discretizes according to the data distribution
    (This variables is not used in the case of the analysis conducted for this assignment since KNN does not require discretized variables)
    -make_dummies: turns a discrete function into dummy variables.

Part 1.B:

    4. Build and evaluate classifier


    -drop_feats: Deletes variables that we don't want to include as predictive feature
    -split: Splits data into train and test sections.
    - knn_f: Fits model and applies to testing data according to the specificities provided for the adjustment of the model.
    - test_evals: Returns an evaluation measure according to the test
    predictions and true values, according to a given threshold
    and according to the specified measure of evaluation.
    -  test_models:   Tests all possible specifications for a knn model given a set of parameters specified.


The second part of the notebook excecutes the functions that were created on the firs part. I start by creating the pandas frame that is going to be used for the subsequent analysis, as well as by defining lists of variables that are used in the functions. The approach is the followin:

a. For all variables, we get the descriptive statistics, and meassures of missing values (by percentages). I also carry out scatter plots and pearson coefficient to meassure how variables relate to each other and how they relate to the dependent variable. I also run the same statistical analysis for some of these variables grouped at the zip code level. We see, for example, that in ZC 60644 there are little probabilities of experienced 90 days past due delinquency. It also happens to be an area with a slighter older population, and higher monthly income.
Scatter plots are not very intuitive for this case since we have a discrete outcome variable, but we can see a different distribution in the opposite sides of the outcome variable for some features such as number of dependents, monthly income, and debt ratio. The plots also help us identify outliers.

Finally, we run a nested loop in order to adjust in many different ways the KNN model, and to find the one that gives a best accuracy score according to the test section of the data.The best model Ifound, with a threshold of .5, is a model with a low score for accuracy (.92), with p = 4, number of neighbohrs = 10, and with uniform weighs. 
