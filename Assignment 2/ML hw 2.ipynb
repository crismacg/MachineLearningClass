{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MACHINE LEARNING FOR PUBLIC POLICY\n",
    "# Homework 2 - Cristina Mac Gregor Vanegas\n",
    "### Due: April 17, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is organized in the following way: First, all functions created in order to carry out the analysis are defined, for points 1 through 6. On a second part of the notebook, the functions are called ot excecute the analyisis\n",
    "#### PART 1.A:\n",
    "     1. Loading data\n",
    "     2. Exploring data\n",
    "     3. Pre-processing data\n",
    "     4. Generating features and predictors. \n",
    "#### Part 1.B: \n",
    "     5. Building KNN classifier\n",
    "     6. Evaluating the classifier. \n",
    "#### Part 2.A\n",
    "    Running exploatory analysis\n",
    "#### Part 2.B\n",
    "    Running model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1.A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "import geopandas as gpd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_files(file_name):\n",
    "    '''\n",
    "    Reading in downloaded csv files.\n",
    "    '''\n",
    "    dframe = pd.read_csv(file_name)\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring and pre-processing data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_mv(frame, var):\n",
    "    '''\n",
    "    Prints out percentage of missing values for a given variable.\n",
    "    '''\n",
    "    frame[\"temp\"] = frame[var].apply(lambda x: x if float(x) else np.nan)\n",
    "    frame[\"temp2\"] = frame[var].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "    print(\"Missing values\", frame[\"temp2\"].value_counts(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_var(frame, var):\n",
    "    '''\n",
    "    Cleans variables from unwanted characters; removes outliers and fills in missing values \n",
    "    '''\n",
    "    frame[var] = frame[var].apply(lambda x: np.nan if (x == \"-\") else float(x))\n",
    "    \n",
    "    #Winzorizing process: setting outliers to the value of the 99 percentile. \n",
    "    x99 = frame[var].quantile(.99)\n",
    "    print(\"dropping outliers\")\n",
    "    frame[var] = frame[var].apply(lambda x: x99 if x > x99  else x)  \n",
    "    \n",
    "    print(\"setting mv to mean\")\n",
    "    #Setting missing values to be the value of the mean\n",
    "    x50 = frame[var].mean()\n",
    "    print(x50)\n",
    "    frame[var] = frame[var].apply(lambda x: x50 if pd.isnull(x) else x)  \n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(frame, target_var, group_vars = None):\n",
    "    '''\n",
    "    Prints general statistics for each variable, and if specified, also \n",
    "    means of grouped-by varibales, grouped by specified groups. \n",
    "    '''\n",
    "    \n",
    "    if not group_vars :\n",
    "        print(\"\\n\", target_var, frame[target_var].describe())\n",
    "        print(frame[target_var].value_counts(True))\n",
    "    \n",
    "    if group_vars is not None: \n",
    "        print(frame.groupby(group_vars)[target_var].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_geo(shape_file, frame, var, shp_name, level_str):\n",
    "    '''\n",
    "    Creates a geopandas file at the geographical level specified, given a pandas\n",
    "    dataframe and a shape or geojson file.\n",
    "    Inputs: shape_file: shapefile or geojson file\n",
    "            frame: pandas frame\n",
    "            shp_name: name of column in geojson file\n",
    "            level_str: name of column in frame\n",
    "    Outputs:\n",
    "        Extended geo frame (geopandas object)\n",
    "\n",
    "    '''\n",
    "    frame.groupby()\n",
    "    geo_df = gpd.read_file(shape_file)\n",
    "    geo_df = geo_df.rename(columns={shp_name: level_str})\n",
    "    geo_df_ext = geo_df.merge(frame, on=level_str, how = 'left')\n",
    "    return geo_df_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_map_byvar(frame, varbs):\n",
    "    '''\n",
    "    Plots a map of the geographic distribution of the variables we wish to see. \n",
    "    '''\n",
    "    for i in varbs:\n",
    "        geo_df.plot(column=i, cmap='OrRd')\n",
    "        plt.title(i)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_cor(frame):\n",
    "    '''\n",
    "    Prints spearman correlations from a complete dataframe\n",
    "    '''\n",
    "    return frame.corr(\"spearman\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scat(frame, varbs, target_var):\n",
    "    '''\n",
    "    Prints scatter plots for all the possible features against the predicted variable. \n",
    "    '''\n",
    "    pairs = []\n",
    "    for i in varbs:\n",
    "            plt.scatter(frame[target_var], frame[i])\n",
    "            plt.title(\"{} vs {}\".format(target_var, i))\n",
    "            plt.xlabel(target_var)\n",
    "            plt.ylabel(i)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate features functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_equal(frame, var, buckets):\n",
    "    '''\n",
    "    Discretizes a continious variable into the amount of buckets specified\n",
    "    '''\n",
    "    new_name = str(var) + \"_discrete\" \n",
    "    array = frame[var]\n",
    "    dif = (array.max() - array.min()) / (buckets - 1)\n",
    "    small_temp = array.min()\n",
    "    largest_temp = array.min() + dif\n",
    "    group = 1     \n",
    "    while largest_temp <=  array.max():\n",
    "        frame[new_name] = frame.apply(lambda x: group if (small_temp <= x) and (x < largest_temp) else x[new_name])\n",
    "        group = group + 1\n",
    "        small_temp = largest_temp\n",
    "        largest_temp = largest_temp + dif       \n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretize_quartiles(frame, var, buckets):\n",
    "    '''\n",
    "    Discretizes a continious variable into the amount of buckets specified\n",
    "    '''\n",
    "    new_name = str(var) + \"_discrete_q\" \n",
    "    x25 = frame[var].quantile(.25)    \n",
    "    x50 = frame[var].quantile(.50)    \n",
    "    x75 = frame[var].quantile(.75)  \n",
    "    group = 1 \n",
    "    last = 0\n",
    "    for i in [x25, x50, x75]:\n",
    "        frame[new_name] = frame[var].apply(lambda: group if (x <= i) and (x > last)) \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dummies(frame, var, threshold = None):\n",
    "    '''\n",
    "    Makes dummy variables for each category of a discrete variable. \n",
    "    '''\n",
    "    if threshold: \n",
    "        new_name = str(var) + \"_d\" \n",
    "        frame[new_name] = frame.apply(lambda x: 1 if x[var] < threshold else 0)\n",
    "    else:\n",
    "        buckets = len(frame[var].value_counts())\n",
    "        for i in buckets: \n",
    "            new_name = str(var) + \"_d_\" + str(i)\n",
    "            frame[new_name] = frame.apply(lambda x: 1 if x[var] == i else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1.B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_feats(varbs, frame):\n",
    "    '''\n",
    "    Deletes variables that we don't want to include as predicitve features\n",
    "    '''\n",
    "    f2 = frame.drop(varbs, axis=1)\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(frame, test_percentage, target_var):\n",
    "    '''\n",
    "    Splits data into train and test sections. \n",
    "    '''\n",
    "    X = frame.drop(target_var, axis=1)\n",
    "    Y = frame[target_var]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_percentage)\n",
    "\n",
    "    return  x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_f(x_tr, y_tr, x_tst, y_tst, nn = 10, p =3, weights_ = 'distance'):\n",
    "    '''\n",
    "    Fits model and applies to testing data according to the specificities provided\n",
    "    for the adjustment of the model.\n",
    "    '''\n",
    "    knn = KNeighborsClassifier(n_neighbors=nn, metric='minkowski', metric_params={'p': p}, weights=weights_)\n",
    "    knn.fit(x_tr, y_tr)\n",
    "    preds = knn.predict_proba(x_tst)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_evals(output_array, real_vals, evals, threshold):\n",
    "    '''\n",
    "    Returns an evaluation meassure according to the test\n",
    "    predictions and true values, according to a given threshold\n",
    "    and according to the specified meassure of evaluation. \n",
    "    Inputs:\n",
    "        output_array: (array) predicted values from test fraction of the data\n",
    "        real_vals: (array) true values from test fraction of data (y_test)\n",
    "        evals: (str) meassure of evaluation. Can be accuracy, recall, precision \n",
    "                    or specificity\n",
    "        threshold: (float) threshold for predicted probabilities. \n",
    "    Outputs: \n",
    "        Score (float)\n",
    "    '''\n",
    "    \n",
    "    test = {'pred': list(output_array), 'real': real_vals}\n",
    "    test_f = pd.DataFrame(data=test)\n",
    "    test_f['pred_bool'] = test_f['pred'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "   \n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    \n",
    "    for indx, row in test_f.iterrows():\n",
    "        if (row[\"pred\"] == 1) and (row[\"real\"]==1):\n",
    "            TP += 1\n",
    "        if (row[\"pred\"] == 1) and (row[\"real\"]==0):\n",
    "            FP += 1\n",
    "        if (row[\"pred\"] == 0) and (row[\"real\"]==0):\n",
    "            TN += 1\n",
    "        if (row[\"pred\"] == 0) and (row[\"real\"]==1):\n",
    "            FN += 1\n",
    "            \n",
    "    if evals == 'accuracy':\n",
    "        return (TP + TN) / (TP + TN + FP + FN)\n",
    "    elif evals == 'recall':\n",
    "        return (TP) / (TP + FN)\n",
    "    elif evals == 'precision':\n",
    "        return (TP) / (TP + FP )\n",
    "    elif evals == 'specificity':\n",
    "        return (TN) / (TN + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(pvals, numn, weights, tested_param, threshold):\n",
    "    '''\n",
    "    Tests all possible specifications for a knn model given \n",
    "    -pvals (tuple) : the range of values for p in the knn model specification\n",
    "    -numn (list) : the values of number of nieghbohrs that we want to test\n",
    "    -weights (list) : kind of weights applied \n",
    "    -tested_param (str): meassure of evaluation. Can be accuracy, recall, precision \n",
    "                    or specificity\n",
    "    -threshold (float):  threshold for predicted probabilities. \n",
    "    Outputs the information for the best model. \n",
    "    '''\n",
    "    accuracy = 0 \n",
    "    for p_vals in range(pvals[0], pvals[1]):\n",
    "        for num_n in numn:\n",
    "            for w in weights:\n",
    "                pred = knn_f(xtrain, ytrain, xtest, ytest, num_n, p_vals, w)\n",
    "                score_ = test_evals(pred, ytest, tested_param, threshold)\n",
    "                \n",
    "                if score_ > accuracy:\n",
    "                    keep = (p_vals, num_n, w, score_)\n",
    "                    accuracy = score_\n",
    "    \n",
    "    return keep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2.A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"data/credit-data.csv\"\n",
    "geo = \"data/chi_boundaries_zip.geojson\"\n",
    "fr = read_files(csv)\n",
    "fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_vars = [\"SeriousDlqin2yrs\", \"RevolvingUtilizationOfUnsecuredLines\", \"age\", \n",
    "            \"zipcode\", \"NumberOfTime30-59DaysPastDueNotWorse\", \"DebtRatio\", \n",
    "            \"MonthlyIncome\",\"NumberOfOpenCreditLinesAndLoans\", \"NumberOfTimes90DaysLate\", \n",
    "            \"NumberRealEstateLoansOrLines\", \"NumberOfTime60-89DaysPastDueNotWorse\",\n",
    "            \"NumberOfDependents\"]\n",
    "\n",
    "for i in all_vars:\n",
    "    print (\"******\", i,\"****** \\n\")\n",
    "    print(\"Missing values percentages; 0 = not missing; 1 = mv\")\n",
    "    check_mv(fr, i)\n",
    "    print(\"-----------\")\n",
    "    get_stats(fr, i)\n",
    "    print(\"----------- \\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = show_cor(fr)\n",
    "x #shows correlation grid \n",
    "\n",
    "#we are particularly interested in the way seriousDIqin2yrs is related to other variables. We see that variables who have higher relation are Revolving Utilization of Unsecuted lines, and all the variables counting the number of times late, in particular the number of times 90 days late.\n",
    "#Since, in turn, NumberOfTimes90DaysLate is relatively highly correlated with those meassuring DaysPastDueNotWorse, we will only focus on this variable from this group. \n",
    "\n",
    "# Age seems to be relatively strong, but zipcode and number of dependents seems less strongly correlated. We proceed to \n",
    "# observe dinamics grouping by zipcode and number of dependents. Monthly income is moderately and negatively correlated with \n",
    "# the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vars_selected = [\"SeriousDlqin2yrs\", \"age\", \"DebtRatio\", \n",
    "            \"MonthlyIncome\", \"NumberOfOpenCreditLinesAndLoans\", \n",
    "            \"NumberRealEstateLoansOrLines\", \"NumberOfDependents\"]\n",
    "\n",
    "#Printing stats by zipcode\n",
    "for i in vars_selected: \n",
    "    print (\"******\", i,\"****** \\n\")\n",
    "    get_stats(fr, i, \"zipcode\")\n",
    "    print(\"----------- \\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_percentage = .3\n",
    "# we can also further loop changing test percentage. \n",
    "vars_remove = [\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"temp\", \"temp2\"]\n",
    "fr2 = drop_feats(vars_remove, fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [\"RevolvingUtilizationOfUnsecuredLines\", \"age\", \n",
    "         \"zipcode\",\"DebtRatio\", \"MonthlyIncome\",\"NumberOfOpenCreditLinesAndLoans\", \n",
    "          \"NumberOfTimes90DaysLate\", \"NumberRealEstateLoansOrLines\",\n",
    "         \"NumberOfDependents\"]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = split(fr2, test_percentage, \"SeriousDlqin2yrs\")  \n",
    "for i in xtrain, xtest: \n",
    "    for v in feats:         \n",
    "        clean_var(i, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = (1, 10)\n",
    "numn = [1,5,10,20,40,80,100]\n",
    "ws = ['uniform','distance']\n",
    "test_param = 'accuracy'\n",
    "thresh = .7 #Note: can also loop further with threshold\n",
    "best_model = test_models(pvals, numn, ws, test_param, thresh)\n",
    "print(\"best p:\", best_model[0])\n",
    "print(\"number of neighborhs:\", best_model[1])\n",
    "print(\"w: \", best_model[2])\n",
    "print(\"Score for {}: {}\".format(test_param, best_model[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
